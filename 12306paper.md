##12306 PAPER (YUE LI)
###__Motivation__: 

* People do not use naive short passwords any longer
	* Security systems require users to use more complicated passwords, which may include upper case and lower case letter, numerals, and even special character. The systems usually also have restrictions on the length of passwords
	* In the past works, passwords at most of length 8 are used to do the experiment. It is no longer the case
* Modern offline password cracking algorithm may not work very well with larger user password space
	* One efficient method may be consider the social profile of a user
	* OMEN+ has proved there will be increase when limited user information is provided (username, email, etc). But they did not have large number of data with complete information. OMEN+ cannot exploit these relations completely. 

###__Our contribution__:
* Develop a new algorithm that take user social information into account. These information includes:
	* Name
	* Birthday
	* Gender
	* Email
	* Cellphone number
	* Account username
* Create a metric to measure passwords security
	* Current password measurement tools mostly depend solely on the length and the complexity of composition of passwords, which may not be accurate
	* One insight we took is that even complex passwords may not be strong if the password is highly related to the user For say, Chris19880808! may be considered secure for an online password measurement tool. But actually it can be easily guessed out
### __Remarks__:
* We do not need to touch Time Memory Trade Off because we have plain text data and we focus on decreasing the number of guesses (Like most of modern papers). 

----
####Password Cracking -- Background

####Related Paper (==Click to jump to corresponding sections==)
[A Cryptanalytic time-memory trade-off](#TMTO) by M. Hellman (Information Theory, IEEE 1980)

[Making a faster cryptanalytic time-memory trade-off](#Rainbow) by P. Oechslin (CRYPTO 2003)

[Fast Dictionary Attacks on Passwords Using Time-Space Tradeoff](#Markov) by A. Narayanan (CCS 2005)

[Password Cracking Using Probabilistic Context-Free Grammars](#PCFG) by M. Weir (S&P 2009)

<a name = "METRIC"></a>[Testing metrics for password creation policies by attacking large sets of revealed passwords 
(==TO BE ADDED==)](#METRIC) (CCS 2010)

[Adaptive Password-Strength Meters from Markov Models](#AdaptMeter) by C. Casterlluccia (NDSS 2012)

[Password Cracking Based on Learned Patterns from Disclosed Passwords](#PCFGLIKE) (ICIC2013)

[When Privacy meets Security: Leveraging Personal Information for Password Cracking](#OMEN) by M. Durmuth (2013)

[Telepathwords:Preventing Weak Passwords by Reading Users' Minds](#Telepathwords) by C. Herley (USENIX Security 2014)

[A Large-Scale Empirical Analysis of Chinese Web Passwords](#ChinesePass) by Z. Li (USENIX Security 2014)

<a name = "SEMANTIC"></a> [On the Semantic Patterns of Passwords and their Security Impact](#SEMANTIC) by R. Veras (NDSS 2014)

#### [HERE](#REMARK) are Some General Remarks 
#### [HERE](#RESULT) are Initial Results
---
### RELATED PAPERS
---

#### <a name="Markov"></a> Review on __Fast Dictionary Attacks on Passwords Using Time-Space Tradeoff__
 * Insight 
   * The distribution of letters in easy-to-remember passwords is likely to be similar to the distribution of letters in the users' lative languages
   * A significant number of passwords are neither dictionary words nor total random sequences.
   * Phonetic similarity with words in the user's native language is a major contributor to memorability
 * Approach:
   * Use Markov Model in NLP to capture the phonetic similarity in human languages
   * Use finite automata to adapt to the non-alphabetic requirement (a\* or a \*n\*, etc)
   * Efficiengtly enumerate strings of a given length that satisfy a markovian filter and a deterministic finite automaton. 
 * Markovian Filtering:
   * $P(x_1x_2x_3...x_n) = v(x_1)\prod_{i=1}^{n-1}v(x_{i+1}|x_i)$
   * Introduced a threshold to discretize the probability intot 2 levels (There are more levels in other papers)
 * Filtering with a finite automaton:
   * Simply use a set of regular expressions such as "One upper case followed by lower cases"
 * Time Space Trade Off (When lookup is faster than encryption)
   * Can take advantageof Time Space Trade Off.
   * Give an index i to the keyspace, the $i^{th}$ key will be returned. 

####<a name = "AdaptMeter"></a> Review on Adaptive Password-Strength Meters from Markov Models
* Motivation:
  * Pssword distributions are different in different sites.
* Challenges
  * Security: How to ensure security even the n-gram database is leaked (Main contribution of this paper)
  * Accuracy: The meter needs to correctly gauge the strengh of a password.
* Markov Models
  * In an n-gram: $P(c_i|c_{i-n+1},...c_{i-1}) = {count(c_{i-n+1},...,c_{i-1},c_i)\over \sum_{x \in Language}(c_{i-n+1},...,c_{i-1},x)}$
  * Language composed of 38 characters -- [a-z][0-9][U][S], in which U and S represent all upper case and all special symbols
* ALgorithm:
  * Keep n-gram counts $count(c_{i-n+1},...,c_{i-1},c_i)$, initialize all the counts to 0
  * Whenever a password is added, it is decomposed into n-grams. $count(c_i,...,c_{i+n-1})$ = $count(c_i,...,c_{i+n-1})$+1 for each i = 1,...,l (l is the number of n-grams)
  * Noise is added to the database by increasing each individual n-gram's count by one with probability $\lambda$ independently. 
  * Store the password hash with salt as usual
* Example:
  * The probability of the string password (with n =5) is computed as follows:
  $P(password) = P(p)P(a|p)P(s|pa)P(s|pas)P(w|pass)...P(d|swor)$
  * Pick one of the elements as an example: 
  $p(o|assw) = {count(asswo)\over count(assw)} = {98450 \over 101485}=0.97$ and the overall estimation of passwod is 0.0016
#### <a name="TMTO"></a> Review on __A Cryptanalytic time-memory trade-off__:
 * Senario: brute-force cracking encryption key knowing the plaintext and ciphertext
 * Two extreme
   * exhaustive search (number of operations needed (T) equal to the key space (N) while not requiring excessive memory)
   * table lookup (number of memory needed (M) equal to the key space (N) while not requiring excessive operations, The N operations for constructing the table does not count because it is reusable. The attacker can do this precomputation at his leisure)
 * M+T is the complexity. $M=T=N^{({2\over3})}$ can be obtained to solve the problem, which reduces the work for brute-forcing DES (56 bits back then) to less than 38 bits work. 
 * Iterative Approach
   * Construct tables with reduction function (maps ciphertext back to plaintext using all possible keys)
    * m tables and each with length t
    * stores only the start point and end point
    * apply reduction function to the ciphertext and compare to the end point iteratively, try out the matched plaintext.
    * If a match is made, reconstruct the key using the start point.
   * Overall there are $M=N^{{2\over3}}$ ($N^{{1\over3}}$ Tables (Note that each table use a different reduction function), each with m = $N^{{1\over3}}$ words. And the overall operation number is $N^{{2\over3}}$ ($N^{{1\over3}}$ for each table).
 * Note:
   * This method has the following drawbacks: It cannot prevent collision and merge. Loops are hard to detect
   * A major improvement is to use distinguished points by Ron Rivest(points with simple rules, e.g. consecutive 10 0s in the beginning). Distinguished points have solutions to the prementioned problems. Besides, it reduces the look up time since only key that satisfying the rule needs to be looked up in the table.[See here](http://www.h-online.com/security/features/Hellman-and-Rivest-746294.html)


---
####<a name="OMEN"></a> Review on When Privacy meets Security: Leveraging Personal Information for Password Cracking
* Based on Markov Model, this paper introduces OMEN (Ordered Markov Enumerator)
  * It presents a more effiicent implementation of password enumeration based on Markov Models.
  * This algorithm does not use finiate automaton to restrict guesses. Instead it solely use a Markov Model
* An improved Enumeration Algorithm:
  * The original Markov Model by Narayanan does not output passwords in order of decreasing probability. OMEN can enumerate passwords in an approximately decreasing probability.
  * They do the ordered enumeration by discretizing all probabilities into a number of bins(levels) and iterating all bins in order of decreasing likelihood. 
  * The levels are computed as follows
  $l_i = round(log(c_1.prob_i+c_2)$, in which c1 and c2 are constants and tuned to get 10 different levels (Levels are corresponding to grams not password guesses).
* The enumeration proceeds as follows using 3-grams(with length $l$ and level $\eta$, enumPwd($\eta,l$)):
  1. Identifies all vectors __a__=$(a_2,a_3,...,a_l)$, such that each $a_i$ is an integer in the range [0,9] (10 bins), and the sum of all elements is $\eta$.
  2. Output the guesses in decreasing order of $\eta$
  
* Examples:
$$
L(aa) = 0, L(ab) = -1\\
L(ba) = 0, L(bb) = 0
$$
and transitions have levels
$$
L(a|aa) = -1, L(b|aa) = -1 \\
L(a|ab) = 0, L(b|ab) = -2 \\
L(a|ba) = -1, L(b|ba) = -1\\
L(A|bb)= 0, L(b|bb) = -2
$$
Starting with $\eta = 0$, which gives vector (0,0), we should try bba
Then with $\eta = -1$, which gives vector (0,-1) and (-1,0). We should try aaa and aab
And so on.

---
####<a name="Rainbow"></a>Review on __Making a faster cryptanalytic time-memory trade-off__:

This paper presents rainbow table, which is derived from the original methods of Hellman, but not compatible with "distinguished points" method. 

 * This method still uses iterative approach to save storage space. The difference from the original methods are as following:
   * there is less tables. In the original method, t of m * t tables are generated while in rainbow table they are "merged"  so a table of size mt * t is generated (They both achieve roughly $mt^2$ key coverage)
   * The reduction function is different for each iteration. The beneficial result is that although collision without merging is possible (and very likely they are not merging).
   * Experiment shows that rainbow table is 7 times faster than the original method while achieving no less coverage. 


One point from online source states that there is no absolute winner between rainbow table and distinguished points method [See here](http://www.h-online.com/security/features/Rainbow-tables-746296.html). The main idea is that rainbow table has a better table structure so the calculation is halved (__Not quite understandable__). In addition, there is less false alarm and constant chain length. However, the distinguished points method has much less table lookups. 


####<a name = "PCFG"></a> Review on __Password Cracking Using Probabilistic Context-Free Grammars:__
 * Scenario: A smart brute-force password cracking method.
 * Content:
 There are 2 main contributions. 
 The first is the PCFG based password cracking method, which learns the structures of the passwords in the training set. The method will compute the probability of each structure and output the guesses in a decreasing probability order.
 The second contribution is that they present a "NEXT" function to output the guesses in decreasing order. "NEXT" function is proven to be correct and will output unique guesses. 
 * Highlight:
   * Generate word-mangling rules from the training set. That is to say, this method will learn the most probable structure of the password and try the passwords with this structure.
   * Generate in a decreasing probability order (Not strictly but mostly). 
   * Beats John the Ripper, which has markov based password cracking implemented
   * Used around 80K passwords for experiments.
 * Details:

The different forms of the password structure is listed in below table

| Structure | Example |
|-------------:|:-------------|
| Simple | $SLD$ |
| Base      | $S_1L_8D_3$ |
| Pre-terminal | \$$L_8123$|
| Terminal(Guess) |  \$$wordpass123$ |

This PCFG-based method will output pre-terminal or terminal guesses in decreasing probability order.  

1. They first obtain all the base forms of passwords from the training set (Say $S_1L_8D_3$). In this step the result base forms are not many.
2. Compute the possibility of actual content under $S$, $L$ segments. For $S$ segment, examples are that we have "!" and "\$" in $S_1$ with probability of 0.8 and 0.2. For $L$ segment, we may have "123" with probability 0.6 and "000 with probability 0.4. 
3. They then substitute $S$ and $D$ with actual content (In this case, one result we have can be \$$L_8123$, there are also many other possibilities like $!L_8000$). The results are called pre-terminals. In this step the results will be thousands to tens of thousands. All the pre-terminals have a well-defined probability. 
4. Pre-terminals may be sorted by probability. Then we substitute the __L__ Segment with words from dictionaries (In our example "wordpass" is used) and output them as guesses
5. An alternative (and better performance) is to sort the terminal form instead of the pre-terminal form. The probability of each terminal form is computed as the multiplication of its pre-terminal form and the possibility of a word with certain length (This possibility is not real possibility, it is just $1\over N$, in which N is the number of words of the desired length in the dictionary). 

__Possible improvement:__

* To fill the __L (Letter)__ segment, they still use some existing dictionaries to fill the part using each of the word of the same length as described by the __L__ Part (Say all words with length 4 will be filled in the segment $L_4$).  
* When using the terminal form to calculate the possibility, they simply count the number of words of the length designated $N$ and count the possibility of every word to be $1/N$

__Combine Markov Chain based method__
* There is space to combine PCFG and Markov based password cracking models by using some of the technique in Markov model when substituting the Letter segment in PCFG approach. 

-----
####<a name = "PCFGLIKE"></a>Password Cracking Based on Learned Patterns from Disclosed Passwords

This is a method that is very similar to PCFG attack. Basically this paper is of little value. Several differences are:
* Upper case and lower case are differentiated.
* Dictionaries contain dictionary words, keyboard strings (Like asdfghjkl), and Alphabetic strings from the trainig set.
* It cannot enumerate passwords in a decreasing possibility order, instead it introduces a threshold to filter out lower possibility passwords (This is actually even a step back).

-----
####<a name = "Telepathwords"></a>Review on Telepathwords:Preventing Weak Passwords by Reading Users' Minds:
Telepathwords are a online system that provide feedback to the passwords users are trying to type and predict the next character. By doing so users are aware that their passwords are easy to guess.
* Architecture:
  * Unlike many other weak-password-prevention systems which adopt client side javascript for security and performance reason, Telepathwords employs a client-server architecture. Predictions are from server, which is displayed in front-end user interface using JavaScript.
  * To ensure security, they use a custom format to compress and pad responses to a common length and route all communications via HTTPS.
* Prediction Algorithm
  * Telepathwords run multiple predictors and fill the result set with the prediction, reasons, and a score. 
  * Telepathwords contains predictors for common character sequences (from language models and databases of common passwords) , keyboard movements, repeated strings, and interleaved strings.
  * Scores for strings are calculated through their frequencies.


-----
####<a name="ChinesePass"></a> Review on __A Large-Scale Empirical Analysis of Chinese Web Passwords:__
Highlight:

* This paper does not introduce new technique to password cracking. They are using the standard PCFG-based cracking method (Just add some words in the dictionaries and adjust a little the probability)
* The paper is mainly about comparing Chinese passwords and English passwords. Some results are presented in this paper

Their results are:
1. Chinese Passwords are more congregated (Not sparse as English passwords because of limited vocabulary). 
2. Chinese passwords have more digit-only passwords.
3. The character distribution is different between the 2 groups.
4. Chinese passwords are more prone to take advantage of keyboard stroke patterns.
5. Chinese Pinyin is a very important building block of Chinese passwords.
6. People like to use dates in their passwords. Chinese passwords put YYYY in front while English passwords put it in the end.
7. They use some metrics to measure the resistance to guessing. They conclude that it is easier to guess a small portion of Chinese passwords but for a majority of Chinese passwords, guessing them becomes as hard as guessing English ones. In addition, a considerable number of Chinese users still choose their passwords carefully.
8. Cross-site guessing is harder


They also introduce an algorithm to identify Pinyins or English words. 

They wish to show their results are useful in help cracking Chinese passwords. That is to say, given an English dataset, is there anything we can do to crack Chinese dataset? Then they did some minor change on PCFG-based algorithm to help cracking Chinese passwords, they are:
1. They add 20,000 most frequently used Pinyins in the dictionaries. (Chinese users tend to use Pinyin instead of English words)
2. They add six-digit and eight-digit numbers to the English training set. (Chinese users like date and the composition of date is different from English users)

They have achieved up to 34% increasing in cracking Chinese dataset. They have the following result:
1. Pinyin and dates play an important role in guessing Chinese Passwords
2. The distribution of password categories (The base form of PCFG method) is not very important. It is the string that matters.

###<a name="REMARK"></a>__REMAKRS__

__Practices of TMTO (Time memory trade-off):__
 * Scenarios: Cracking the key of the encryption, given known __plaintext__ and __ciphertext__. 
 HOW: Encrypt the plaintext using all possible values of keys and compare the ciphertext (2 extremes mentioned in A Cryptanalytic Time-Space Trade-Off). 
   * In the tables $f(K) = R[S_K(P_0)]$, __Keys__ are stored in the tables.

 * Scenarios: Cracking the plaintext, given the __hash function(Say MD5 or SHA1)__ and __ciphertext__.
 HOW: Encrypt all possible values (Usually not be the entire password space) of plaintext and compare the ciphertext.
   * In the tables $f(P) = R[S_{K_0}(P)]$, __Passwords__ are stored in the table

__What is dictionary attack__:
 Scenario: Given a hash value, finding out the corresponding plaintext.
 The most basic attack is based on a large table which accomodates a large number of possible plaintext and hash values. By searching through the entire table one may possibly find the possible plaintext (As the space is not equal in the two mapping sides, there should be infinite plaintext that maps to one certain hash value. The plaintext should be at hand or meaningful to regard as correct). 
 Dictionary Attacks are useful in __Password Cracking__. There are several optimizations:

 * Using meaningful words to crack the passwords because people passwords are usually memorable, and thus having semantic and syntactic indication. 
 * Add dangling rules (appending or suffixing a digit) to adapt to modern passwords composition rules.

__Why Salt in Password Storage:__
 Salt will disable the pre-computation attacks such as TMTO and rainbow table because salt is different for every password. Pre-computation method (rainbow table) store commonly used passwords (Otherwise the rainbow table would be very large). If the password are salted, there is no way a rainbow table would contain something like "!@^$!&@(#secret" (__Actually the very first version of rainbow table (2003) contains all potential possible passwords within a length (say of length 8, of course having salt enabled will drastically increase the password length, leading a vast extension of password space. I believe in practical implementation, rainbow table will just contain the commonly used words__). Therefore rainbow table cannot usually find the result. 
 In conclusion, __Salt is usually used to prevent pre-computation attacks__.


###<a name="RESULT"></a> Preliminary Results
asdfjasdfaksdlfj
sadfasdfasdfds