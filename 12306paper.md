### Feb 5 2015
----
###__Motivation__: 

* People do not use naive short passwords any longer
	* Security systems require users to use more complicated passwords, which may include upper case and lower case letter, numerals, and even special character. The systems usually also have restrictions on the length of passwords
	* In the past works, passwords at most of length 8 are used to do the experiment. It is no longer the case
* Modern offline password cracking algorithm may not work very well with larger user password space
	* One efficient method may be consider the social profile of a user
	* OMEN+ has proved there will be increase when limited user information is provided (username, email, etc). But they did not have large number of data with complete information. OMEN+ cannot exploit these relations completely. 

###__Our contribution__:
* Develop a new algorithm that take user social information into account. These information includes:
	* Name
	* Birthday
	* Gender
	* Email
	* Cellphone number
	* Account username
* Create a metric to measure passwords security
	* Current password measurement tools mostly depend solely on the length and the complexity of composition of passwords, which may not be accurate
	* One insight we took is that even complex passwords may not be strong if the password is highly related to the user For say, Chris19880808! may be considered secure for an online password measurement tool. But actually it can be easily guessed out

----
###Password Cracking -- Background

Paper to read:
__A Cryptanalytic time-memory trade-off__ by M. Hellman
__Making a faster cryptanalytic time-memory trade-off__ by P. Oechslin
__Fast Dictionary Attacks on Passwords Using Time-Space Tradeoff__ by A. Narayanan
__When Privacy meets Security: Leveraging Personal Information for Password Cracking__ by M. Durmuth

---
### Feb 7 2015
Review on __A Cryptanalytic time-memory trade-off__:

> * Senario: brute-force cracking encryption key knowing the plaintext and ciphertext
> * Two extreme
>   * exhaustive search (number of operations needed (T) equal to the key space (N) while not requiring excessive memory)
>   * table lookup (number of memory needed (M) equal to the key space (N) while not requiring excessive operations, The N operations for constructing the table does not count because it is reusable. The attacker can do this precomputation at his leisure)
> * M+T is the complexity. $M=T=N^{({2\over3})}$ can be obtained to solve the problem, which reduces the work for brute-forcing DES (56 bits back then) to less than 38 bits work. 
> * Iterative Approach
>   * Construct tables with reduction function (maps ciphertext back to plaintext using all possible keys)
>    * m tables and each with length t
>    * stores only the start point and end point
>    * apply reduction function to the ciphertext and compare to the end point iteratively, try out the matched plaintext.
>    * If a match is made, reconstruct the key using the start point.
>   * Overall there are $M=N^{{2\over3}}$ ($N^{{1\over3}}$ Tables (Note that each table use a different reduction function), each with m = $N^{{1\over3}}$ words) and the overall operation number is $N^{{2\over3}}$ ($N^{{1\over3}}$ for each table).
> * Note:
>   * This method has the following drawbacks: It cannot prevent collision and merge. Loops are hard to detect
>   * A major improvement is to use distinguished points by Ron Rivest(points with simple rules, e.g. consecutive 10 0s in the beginning). Distinguished points have solutions to the prementioned problems. Besides, it reduces the look up time since only key that satisfying the rule needs to be looked up in the table.[See here](http://www.h-online.com/security/features/Hellman-and-Rivest-746294.html)

---
### Feb 10 2015
Review on __Making a faster cryptanalytic time-memory trade-off__:

This paper presents rainbow table, which is derived from the original methods of Hellman, but not compatible with "distinguished points" method. 

> * This method still uses iterative approach to save storage space. The difference from the original methods are as following:
>   * there is less tables. In the original method, t of m * t tables are generated while in rainbow table they are "merged"  so a table of size mt * t is generated (They both achieve roughly $mt^2$ key coverage)
>   * The reduction function is different for each iteration. The beneficial result is that although collision without merging is possible (and very likely they are not merging).
>   * Experiment shows that rainbow table is 7 times faster than the original method while achieving no less coverage. 


One point from online source states that there is no absolute winner between rainbow table and distinguished points method [See here](http://www.h-online.com/security/features/Rainbow-tables-746296.html). The main idea is that rainbow table has a better table structure so the calculation is halved (__Not quite understandable__). In addition, there is less false alarm and constant chain length. However, the distinguished points method has much less table lookups. 
